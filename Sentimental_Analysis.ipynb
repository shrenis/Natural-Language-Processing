{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loadind the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:\\\\Users\\\\SHRENI\\\\Desktop\\\\VIT\\\\3rd_sem\\\\Dataset\\\\IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Phil the Alien is one of those quirky films where the humour is based around the oddness of everything rather than actual punchlines.<br /><br />At first it was very odd and pretty funny but as the movie progressed I didn\\'t find the jokes or oddness funny anymore.<br /><br />Its a low budget film (thats never a problem in itself), there were some pretty interesting characters, but eventually I just lost interest.<br /><br />I imagine this film would appeal to a stoner who is currently partaking.<br /><br />For something similar but better try \"Brother from another planet\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n",
    "df['review'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Documents into Feature Vectore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "\n",
    "docs = np.array(['The sun is shining',\n",
    "                 'The weather is sweet',\n",
    "                 'The sun is shining, the weather is sweet, and one and one is two'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}\n"
     ]
    }
   ],
   "source": [
    "bag=count.fit_transform(docs)\n",
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 0 1 1 0 1]\n",
      " [2 3 2 1 1 1 2 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency and Inverse Document\n",
    "#Term frequencies alone do not contribute to distinct information\n",
    "#tf-idf (t,d) = tf(t,d) X idf(t,d)\n",
    "#idf(t,d) = log(nd / 1 + df(d,t))\n",
    "#where nd = total number of documents and df(d,t) = number of documents that contain the term t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.43370786 0.         0.55847784 0.55847784 0.\n",
      "  0.43370786 0.         0.        ]\n",
      " [0.         0.43370786 0.         0.         0.         0.55847784\n",
      "  0.43370786 0.         0.55847784]\n",
      " [0.50238645 0.44507629 0.50238645 0.19103892 0.19103892 0.19103892\n",
      "  0.29671753 0.25119322 0.19103892]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer(use_idf = True, norm = 'l2', smooth_idf = True)\n",
    "\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function numpy.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, suppress=None, nanstr=None, infstr=None, formatter=None, sign=None, floatmode=None, **kwarg)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization of Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coder', 'like', 'code', 'and', 'thu', 'they', 'code']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "\n",
    "def stemmer_tokenize(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "\n",
    "stemmer_tokenize('coders like coding and thus they code')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "tfidf =  TfidfVectorizer(strip_accents = None, \n",
    "                        lowercase = False,\n",
    "                       tokenizer = stemmer_tokenize,\n",
    "                       use_idf = True,\n",
    "                       norm = 'l2',\n",
    "                       smooth_idf = True)\n",
    "\n",
    " \n",
    "\n",
    "Y = df.sentiment.values\n",
    "x = tfidf.fit_transform(df.review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-3)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,Y_train,Y_test = train_test_split(x,Y,random_state = 1, test_size = 0.5 ,shuffle = False)\n",
    "\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "#Model\n",
    "clf = LogisticRegressionCV(cv=5,\n",
    "                          scoring = 'accuracy',\n",
    "                          random_state = 0,\n",
    "                          n_jobs = -3,\n",
    "                          verbose = 3,\n",
    "                          max_iter = 300).fit(x_train,Y_train)\n",
    "\n",
    "#Saving the model\n",
    "saved_model = open(\"saved_model.sav\",'wb')\n",
    "\n",
    "#using \n",
    "pickel.dump(clf,saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'saved_model.sav'\n",
    "\n",
    "saved_clf = pickle.load(open(filename,'rb'))\n",
    "\n",
    "#test the saved model on test data\n",
    "saved_clf.score(x_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
